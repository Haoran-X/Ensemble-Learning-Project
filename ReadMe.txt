Ensemble Learning Project
Project Overview
This project focuses on applying ensemble learning techniques to predict outcomes based on a dataset that is pre-processed and divided into training and testing sets. Ensemble learning methods combine multiple machine learning models to improve predictions, reduce variance, and avoid overfitting.

Features
Data Preprocessing: Initial steps involve separating the dataset according to specific criteria, such as country, to ensure the models are trained on relevant data.
Model Training: Various ensemble learning models, including XGBoost, Random Forest, Gradient Boosting, AdaBoost, and Bagging with Decision Trees, are trained on the dataset.
Hyperparameter Optimization: Utilization of libraries like Optuna for optimizing model parameters to achieve better performance.
Evaluation: Models are evaluated using metrics like Mean Squared Error (MSE), RÂ² score, and Spearman's rank correlation to assess their accuracy and reliability.

Technologies Used
Python
Pandas & NumPy for data manipulation
Scikit-learn for model training and evaluation
XGBoost for gradient boosting
Optuna for hyperparameter optimization
Matplotlib & Seaborn for visualization

Getting Started
Prerequisites
Ensure you have Python installed on your machine along with the following libraries: Pandas, NumPy, Scikit-learn, XGBoost, Optuna, Matplotlib, and Seaborn.

Contributors
Hanwen Xu, Haoran Xiong, Wenxin Wu, Zihao Yin